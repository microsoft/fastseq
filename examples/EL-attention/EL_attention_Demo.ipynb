{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xZnWgQ1o7yW",
        "outputId": "fb630728-01e2-4cbc-c509-4874c97d8d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue May 25 01:05:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5ZMwI9N5fvR"
      },
      "source": [
        "# Prerequirement (install library and download data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipS-Ptqupa1X",
        "outputId": "d7cd49e3-4183-40b2-fcbc-35706a606c93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fairseq==v0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 28.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==v0.9.0) (1.14.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==v0.9.0) (0.29.23)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==v0.9.0) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==v0.9.0) (2019.12.20)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==v0.9.0) (1.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==v0.9.0) (4.41.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==v0.9.0) (2.20)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==v0.9.0) (3.7.4.3)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.9.0-cp37-cp37m-linux_x86_64.whl size=2122224 sha256=0ddc8b57adfeca6b8f976be2c1524f3220a14485593cb4858b6491512086fe3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n",
            "Successfully built fairseq\n",
            "Installing collected packages: portalocker, sacrebleu, fairseq\n",
            "Successfully installed fairseq-0.9.0 portalocker-2.0.0 sacrebleu-1.5.1\n",
            "Collecting git+https://github.com/microsoft/fastseq.git\n",
            "  Cloning https://github.com/microsoft/fastseq.git to /tmp/pip-req-build-k960o0y_\n",
            "  Running command git clone -q https://github.com/microsoft/fastseq.git /tmp/pip-req-build-k960o0y_\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from fastseq==0.0.4) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from fastseq==0.0.4) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastseq==0.0.4) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastseq==0.0.4) (2.23.0)\n",
            "Collecting rouge-score>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastseq==0.0.4) (20.9)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from fastseq==0.0.4) (1.8.1+cu101)\n",
            "Collecting pytorch-transformers==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/b5/2d78e74001af0152ee61d5ad4e290aec9a1e43925b21df2dc74ec100f1ab/pytorch_transformers-1.0.0-py3-none-any.whl (137kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 33.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->fastseq==0.0.4) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastseq==0.0.4) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastseq==0.0.4) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastseq==0.0.4) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastseq==0.0.4) (2.10)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score>=0.0.4->fastseq==0.0.4) (3.2.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastseq==0.0.4) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->fastseq==0.0.4) (3.7.4.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.0.0->fastseq==0.0.4) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.0.0->fastseq==0.0.4) (4.41.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/f5/06e099d85c66c68f203b356117e9df68e98983f2120b9ae598dc840c20e2/boto3-1.17.79-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 49.2MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.7MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.79\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/e5/f49beffe2474490a5e7811d533049a4fb701a6f87c66e55724a6b11c25e2/botocore-1.20.79-py2.py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 54.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.79->boto3->pytorch-transformers==1.0.0->fastseq==0.0.4) (2.8.1)\n",
            "Building wheels for collected packages: fastseq\n",
            "  Building wheel for fastseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastseq: filename=fastseq-0.0.4-cp37-cp37m-linux_x86_64.whl size=2045769 sha256=45345756fa195425399ef7befcabda72f75c7d1a9a887555c76d520f73ea30cd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sup1cv57/wheels/e5/5f/c6/d125e11cb1c4f959e69ec2a8670a290561359566e5cb6966a1\n",
            "Successfully built fastseq\n",
            "\u001b[31mERROR: botocore 1.20.79 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: rouge-score, sentencepiece, jmespath, botocore, s3transfer, boto3, pytorch-transformers, fastseq\n",
            "Successfully installed boto3-1.17.79 botocore-1.20.79 fastseq-0.0.4 jmespath-0.10.0 pytorch-transformers-1.0.0 rouge-score-0.0.4 s3transfer-0.4.2 sentencepiece-0.1.95\n"
          ]
        }
      ],
      "source": [
        "!pip install fairseq==v0.10.2\n",
        "!pip install git+https://github.com/microsoft/fastseq.git\n",
        "\n",
        "#!git clone https://github.com/NVIDIA/apex\n",
        "#!sed -i 's/if (bare_metal_major != torch_binary_major) or (bare_metal_minor != torch_binary_minor):/if False:/' ./apex/setup.py\n",
        "#!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsnnkjHV4VHq",
        "outputId": "751fe3ec-cf88-4861-8734-3c5b358d34b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-05-25 01:07:00--  https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/for_bart/test.source\n",
            "Resolving fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)... 52.239.237.36\n",
            "Connecting to fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)|52.239.237.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45641783 (44M) [text/plain]\n",
            "Saving to: ‘data/test.source’\n",
            "\n",
            "test.source         100%[===================>]  43.53M  19.8MB/s    in 2.2s    \n",
            "\n",
            "2021-05-25 01:07:03 (19.8 MB/s) - ‘data/test.source’ saved [45641783/45641783]\n",
            "\n",
            "--2021-05-25 01:07:03--  https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/for_bart/test.target\n",
            "Resolving fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)... 52.239.237.36\n",
            "Connecting to fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)|52.239.237.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3559525 (3.4M) [text/plain]\n",
            "Saving to: ‘data/test.target’\n",
            "\n",
            "test.target         100%[===================>]   3.39M  6.78MB/s    in 0.5s    \n",
            "\n",
            "2021-05-25 01:07:03 (6.78 MB/s) - ‘data/test.target’ saved [3559525/3559525]\n",
            "\n",
            "--2021-05-25 01:07:04--  https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/test.source-target.source.bin\n",
            "Resolving fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)... 52.239.237.36\n",
            "Connecting to fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)|52.239.237.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17100598 (16M) [application/octet-stream]\n",
            "Saving to: ‘data/bin/test.source-target.source.bin’\n",
            "\n",
            "test.source-target. 100%[===================>]  16.31M  13.2MB/s    in 1.2s    \n",
            "\n",
            "2021-05-25 01:07:05 (13.2 MB/s) - ‘data/bin/test.source-target.source.bin’ saved [17100598/17100598]\n",
            "\n",
            "--2021-05-25 01:07:05--  https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/test.source-target.source.idx\n",
            "Resolving fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)... 52.239.237.36\n",
            "Connecting to fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)|52.239.237.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 137906 (135K) [application/octet-stream]\n",
            "Saving to: ‘data/bin/test.source-target.source.idx’\n",
            "\n",
            "test.source-target. 100%[===================>] 134.67K   688KB/s    in 0.2s    \n",
            "\n",
            "2021-05-25 01:07:06 (688 KB/s) - ‘data/bin/test.source-target.source.idx’ saved [137906/137906]\n",
            "\n",
            "--2021-05-25 01:07:06--  https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/test.source-target.target.bin\n",
            "Resolving fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)... 52.239.237.36\n",
            "Connecting to fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)|52.239.237.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1598226 (1.5M) [application/octet-stream]\n",
            "Saving to: ‘data/bin/test.source-target.target.bin’\n",
            "\n",
            "test.source-target. 100%[===================>]   1.52M  3.06MB/s    in 0.5s    \n",
            "\n",
            "2021-05-25 01:07:07 (3.06 MB/s) - ‘data/bin/test.source-target.target.bin’ saved [1598226/1598226]\n",
            "\n",
            "--2021-05-25 01:07:07--  https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/test.source-target.target.idx\n",
            "Resolving fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)... 52.239.237.36\n",
            "Connecting to fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)|52.239.237.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 137906 (135K) [application/octet-stream]\n",
            "Saving to: ‘data/bin/test.source-target.target.idx’\n",
            "\n",
            "test.source-target. 100%[===================>] 134.67K   695KB/s    in 0.2s    \n",
            "\n",
            "2021-05-25 01:07:07 (695 KB/s) - ‘data/bin/test.source-target.target.idx’ saved [137906/137906]\n",
            "\n",
            "--2021-05-25 01:07:07--  https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/dict.source.txt\n",
            "Resolving fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)... 52.239.237.36\n",
            "Connecting to fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)|52.239.237.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 603290 (589K) [text/plain]\n",
            "Saving to: ‘data/bin/dict.source.txt’\n",
            "\n",
            "dict.source.txt     100%[===================>] 589.15K  1.44MB/s    in 0.4s    \n",
            "\n",
            "2021-05-25 01:07:08 (1.44 MB/s) - ‘data/bin/dict.source.txt’ saved [603290/603290]\n",
            "\n",
            "--2021-05-25 01:07:08--  https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/dict.target.txt\n",
            "Resolving fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)... 52.239.237.36\n",
            "Connecting to fastseq.blob.core.windows.net (fastseq.blob.core.windows.net)|52.239.237.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 603290 (589K) [text/plain]\n",
            "Saving to: ‘data/bin/dict.target.txt’\n",
            "\n",
            "dict.target.txt     100%[===================>] 589.15K  1.53MB/s    in 0.4s    \n",
            "\n",
            "2021-05-25 01:07:09 (1.53 MB/s) - ‘data/bin/dict.target.txt’ saved [603290/603290]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data\n",
        "!wget https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/for_bart/test.source -P data/\n",
        "!wget https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/for_bart/test.target -P data/\n",
        "\n",
        "!mkdir -p data/bin\n",
        "!wget https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/test.source-target.source.bin -P data/bin/\n",
        "!wget https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/test.source-target.source.idx -P data/bin/\n",
        "!wget https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/test.source-target.target.bin -P data/bin/\n",
        "!wget https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/test.source-target.target.idx -P data/bin/\n",
        "\n",
        "!wget https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/dict.source.txt -P data/bin/\n",
        "!wget https://fastseq.blob.core.windows.net/data/tasks/cnn_dm/len-1024.bin/dict.target.txt -P data/bin/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ40BxorphD2",
        "outputId": "6720f603-f167-4e9c-9bc6-7b709105939e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-05-25 01:07:09--  https://dl.fbaipublicfiles.com/fairseq/models/bart.large.cnn.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3715581256 (3.5G) [application/x-tar]\n",
            "Saving to: ‘bart.large.cnn.tar.gz’\n",
            "\n",
            "bart.large.cnn.tar. 100%[===================>]   3.46G  21.4MB/s    in 2m 47s  \n",
            "\n",
            "2021-05-25 01:09:56 (21.2 MB/s) - ‘bart.large.cnn.tar.gz’ saved [3715581256/3715581256]\n",
            "\n",
            "bart.large.cnn/\n",
            "bart.large.cnn/NOTE\n",
            "bart.large.cnn/model.pt\n",
            "bart.large.cnn/dict.source.txt\n",
            "bart.large.cnn/dict.target.txt\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://dl.fbaipublicfiles.com/fairseq/models/bart.large.cnn.tar.gz'\n",
        "!tar xvzf 'bart.large.cnn.tar.gz'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv3SQXyTpWKC"
      },
      "source": [
        "# Using EL-Attention in Command Line Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcbWgC3WQ4e2"
      },
      "source": [
        "Inference with EL-Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZs68SvhVD7p",
        "outputId": "65f1af03-6806-46bf-dec1-71c79095c002"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 2021-05-25 01:11:15,116 /usr/local/lib/python3.7/dist-packages/fastseq/models/__init__.py:17] transformers can not be imported.\n",
            "INFO 2021-05-25 01:11:15,144 /usr/local/lib/python3.7/dist-packages/fastseq/optimizer/fairseq/beam_search_optimizer.py:28] Using Efficient-Lossless Attention optimization\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
            "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n",
            "INFO 2021-05-25 01:11:15,332 /usr/local/lib/python3.7/dist-packages/fastseq/optimizer/fairseq/__init__.py:55] fairseq(v0.9.0) has been optimized by fastseq(v0.0.4).\n",
            "WARNING 2021-05-25 01:11:15,333 /usr/local/lib/python3.7/dist-packages/fastseq/optimizer/transformers/__init__.py:57] transformers can not be imported. Please ignore this warning if you are not using transformers\n",
            "tcmalloc: large alloc 1625169920 bytes == 0x5563b95cc000 @  0x7f0440f35b6b 0x7f0440f55379 0x7f03ed64e25e 0x7f03ed64f9d2 0x7f042af178a5 0x7f043c12d699 0x5563843ddc65 0x55638439e462 0x556384411715 0x55638440c7ad 0x55638439f003 0x55638439eb09 0x5563844e628d 0x5563844551db 0x55638439dbb1 0x55638448efed 0x556384411988 0x55638440c7ad 0x5563842dee2c 0x55638440ebb5 0x55638440c4ae 0x55638439f3ea 0x55638440e32a 0x55638440c4ae 0x55638439f3ea 0x55638440d3b5 0x55638440c4ae 0x55638439f3ea 0x55638440d3b5 0x55638440c4ae 0x55638439f3ea\n",
            "tcmalloc: large alloc 1625169920 bytes == 0x55641a3ae000 @  0x7f0440f35b6b 0x7f0440f55379 0x7f03ed64e25e 0x7f03ed64f9d2 0x7f042af178a5 0x7f043c12d699 0x5563843ddc65 0x55638439e462 0x556384411715 0x55638440c7ad 0x55638439f003 0x55638439eb09 0x5563844e628d 0x5563844551db 0x55638439dbb1 0x55638448efed 0x556384411988 0x55638440c7ad 0x5563842dee2c 0x55638440ebb5 0x55638440c4ae 0x55638439f3ea 0x55638440e32a 0x55638440c4ae 0x55638439f3ea 0x55638440d3b5 0x55638440c4ae 0x55638439f3ea 0x55638440d3b5 0x55638440c4ae 0x55638439f3ea\n",
            "\n",
            "real\t25m19.342s\n",
            "user\t29m29.255s\n",
            "sys\t0m26.392s\n"
          ]
        }
      ],
      "source": [
        "!time fastseq-generate-for-fairseq data/bin/ --path bart.large.cnn/model.pt  --use-el-attn --fp16 --task translation --batch-size 256 --gen-subset test --truncate-source --bpe gpt2 --beam 4 --min-len 55 --max-len-b 140 --no-repeat-ngram-size 3 --lenpen 2.0 --skip-invalid-size-inputs-valid-test > bart.el-attention_256.txt\n",
        "# uncomment above line to run\n",
        "# Expected time: (real\t24m23.314s for inference on T5 in colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0uOvxIq18Gd"
      },
      "source": [
        "Inference with MultiHead-Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LVHnPI7CVNdZ"
      },
      "outputs": [],
      "source": [
        "# !time fairseq-generate data/bin/ --path bart.large.cnn/model.pt --fp16 --task translation --batch-size 32 --gen-subset test --truncate-source --bpe gpt2 --beam 4 --min-len 55 --max-len-b 140 --no-repeat-ngram-size 3 --lenpen 2.0 --skip-invalid-size-inputs-valid-test > bart.multihead-attention_32.txt\n",
        "# uncomment above line to run\n",
        "# fairseq 0.9.0 is compariable with Pytorch 1.6, but in colab its version is 1.8.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCfbk3wuhtYO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuXz8Zzwhs2u",
        "outputId": "2e9a521f-eae5-487c-cc44-3a76ca8d2c4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bart.el-attention_256.txt  bart.large.cnn.tar.gz  sample_data\n",
            "bart.large.cnn\t\t   data\n"
          ]
        }
      ],
      "source": [
        "!ls "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xpZw27qjkoe",
        "outputId": "8182ebeb-6e08-4be2-a846-fb9bde932152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference speed when using el attention\n",
            "| Translated 11490 sentences (944820 tokens) in 1472.9s (7.80 sentences/s, 641.48 tokens/s)\n",
            "| Generate test with beam=4: BLEU4 = 17.18, 36.9/19.4/13.1/9.3 (BP=1.000, ratio=1.203, syslen=933330, reflen=776133)\n",
            "Inference speed when using multihead attention\n"
          ]
        }
      ],
      "source": [
        "!echo 'Inference speed when using el attention'\n",
        "!tail -n 2 bart.el-attention_256.txt\n",
        "\n",
        "!echo 'Inference speed when using multihead attention'\n",
        "#!tail -n 2 bart.multihead-attention_32.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYRMn99r188h"
      },
      "source": [
        "# Using EL-Attention in Python API (Include Caculating ROUGE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ded7T7x6iPb"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ9DG_zq8KqD"
      },
      "source": [
        "Removing '*--n 3200*' if want to inference on whole dataset. \n",
        "\n",
        "For best speed, using **fastseq-generate-for-fairseq ... --use-el-attn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idZceGNOz5tF",
        "outputId": "081e2af7-4957-42cf-9660-3679de16a832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-05-25 01:36:33--  https://raw.githubusercontent.com/microsoft/fastseq/EL-attention-doc/examples/EL-attention/summarize.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3840 (3.8K) [text/plain]\n",
            "Saving to: ‘summarize.py’\n",
            "\n",
            "summarize.py        100%[===================>]   3.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-25 01:36:33 (63.8 MB/s) - ‘summarize.py’ saved [3840/3840]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/microsoft/fastseq/EL-attention-doc/examples/EL-attention/summarize.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsuvH58auvsk",
        "outputId": "049fa56a-8921-4df6-ca84-8f4c3d7184c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 2021-05-25 01:36:34,967 /usr/local/lib/python3.7/dist-packages/fastseq/models/__init__.py:17] transformers can not be imported.\n",
            "INFO 2021-05-25 01:36:34,970 /usr/local/lib/python3.7/dist-packages/fastseq/optimizer/fairseq/beam_search_optimizer.py:28] Using Efficient-Lossless Attention optimization\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
            "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n",
            "INFO 2021-05-25 01:36:35,150 /usr/local/lib/python3.7/dist-packages/fastseq/optimizer/fairseq/__init__.py:55] fairseq(v0.9.0) has been optimized by fastseq(v0.0.4).\n",
            "WARNING 2021-05-25 01:36:35,151 /usr/local/lib/python3.7/dist-packages/fastseq/optimizer/transformers/__init__.py:57] transformers can not be imported. Please ignore this warning if you are not using transformers\n",
            "loading archive file bart.large.cnn/\n",
            "loading archive file bart.large.cnn/\n",
            "tcmalloc: large alloc 1625169920 bytes == 0x5613eea42000 @  0x7f526e1e8b6b 0x7f526e208379 0x7f521a94125e 0x7f521a9429d2 0x7f525820a8a5 0x7f5269420699 0x5613ba0ffc65 0x5613ba0c0462 0x5613ba133715 0x5613ba12e7ad 0x5613ba0c1003 0x5613ba0c0b09 0x5613ba20828d 0x5613ba1771db 0x5613ba0bfbb1 0x5613ba1b0fed 0x5613ba133988 0x5613ba12e7ad 0x5613ba000e2c 0x5613ba130bb5 0x5613ba12e4ae 0x5613ba0c13ea 0x5613ba13032a 0x5613ba12e4ae 0x5613ba0c13ea 0x5613ba12f3b5 0x5613ba12e4ae 0x5613ba0c13ea 0x5613ba13032a 0x5613ba12e7ad 0x5613ba000e2c\n",
            "tcmalloc: large alloc 1625169920 bytes == 0x56144f824000 @  0x7f526e1e8b6b 0x7f526e208379 0x7f521a94125e 0x7f521a9429d2 0x7f525820a8a5 0x7f5269420699 0x5613ba0ffc65 0x5613ba0c0462 0x5613ba133715 0x5613ba12e7ad 0x5613ba0c1003 0x5613ba0c0b09 0x5613ba20828d 0x5613ba1771db 0x5613ba0bfbb1 0x5613ba1b0fed 0x5613ba133988 0x5613ba12e7ad 0x5613ba000e2c 0x5613ba130bb5 0x5613ba12e4ae 0x5613ba0c13ea 0x5613ba13032a 0x5613ba12e4ae 0x5613ba0c13ea 0x5613ba12f3b5 0x5613ba12e4ae 0x5613ba0c13ea 0x5613ba13032a 0x5613ba12e7ad 0x5613ba000e2c\n",
            "| [source] dictionary: 50264 types\n",
            "| [target] dictionary: 50264 types\n",
            "INFO 2021-05-25 01:38:31,740 /usr/local/lib/python3.7/dist-packages/fairseq/file_utils.py:274] https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json not found in cache, downloading to /tmp/tmpl59i6fze\n",
            "1042301B [00:00, 1883121.69B/s]\n",
            "INFO 2021-05-25 01:38:32,790 /usr/local/lib/python3.7/dist-packages/fairseq/file_utils.py:287] copying /tmp/tmpl59i6fze to cache at /root/.cache/torch/pytorch_fairseq/e2aab4d600e7568c2d88fc7732130ccc815ea84ec63906cb0913c7a3a4906a2e.0f323dfaed92d080380e63f0291d0f31adfa8c61a62cbcb3cb8114f061be27f7\n",
            "INFO 2021-05-25 01:38:32,792 /usr/local/lib/python3.7/dist-packages/fairseq/file_utils.py:291] creating metadata file for /root/.cache/torch/pytorch_fairseq/e2aab4d600e7568c2d88fc7732130ccc815ea84ec63906cb0913c7a3a4906a2e.0f323dfaed92d080380e63f0291d0f31adfa8c61a62cbcb3cb8114f061be27f7\n",
            "INFO 2021-05-25 01:38:32,792 /usr/local/lib/python3.7/dist-packages/fairseq/file_utils.py:298] removing temp file /tmp/tmpl59i6fze\n",
            "INFO 2021-05-25 01:38:33,188 /usr/local/lib/python3.7/dist-packages/fairseq/file_utils.py:274] https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe not found in cache, downloading to /tmp/tmppc3g8ybe\n",
            "456318B [00:00, 1282859.39B/s]\n",
            "INFO 2021-05-25 01:38:34,010 /usr/local/lib/python3.7/dist-packages/fairseq/file_utils.py:287] copying /tmp/tmppc3g8ybe to cache at /root/.cache/torch/pytorch_fairseq/b04a6d337c09f464fe8f0df1d3524db88a597007d63f05d97e437f65840cdba5.939bed25cbdab15712bac084ee713d6c78e221c5156c68cb0076b03f5170600f\n",
            "INFO 2021-05-25 01:38:34,011 /usr/local/lib/python3.7/dist-packages/fairseq/file_utils.py:291] creating metadata file for /root/.cache/torch/pytorch_fairseq/b04a6d337c09f464fe8f0df1d3524db88a597007d63f05d97e437f65840cdba5.939bed25cbdab15712bac084ee713d6c78e221c5156c68cb0076b03f5170600f\n",
            "INFO 2021-05-25 01:38:34,011 /usr/local/lib/python3.7/dist-packages/fairseq/file_utils.py:298] removing temp file /tmp/tmppc3g8ybe\n",
            "\n",
            "real\t9m49.515s\n",
            "user\t7m50.919s\n",
            "sys\t0m8.170s\n"
          ]
        }
      ],
      "source": [
        "!time python summarize.py \\\n",
        "    --model-dir bart.large.cnn/ \\\n",
        "    --model-file model.pt \\\n",
        "    --src data/test.source \\\n",
        "    --bsz 320 \\\n",
        "    --out 320_test.hypo \\\n",
        "    --use-el-attn \\\n",
        "    --n 3200\n",
        "\n",
        " # Expected time: (real\t7m36.176s for inference 3200 samples on T5 in colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wWy6E7410Zt",
        "outputId": "3bcd0637-f5bf-466f-ebe0-f926e1a2e38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A French prosecutor says he is not aware of any video footage from on board the plane. German daily Bild and Paris Match claim to have found a cell phone video of the crash. A French Gendarmerie spokesman calls the reports \"completely wrong\" and \"unwarranted\" German airline Lufthansa says co-pilot Andreas Lubitz battled depression years before he took controls.\n",
            "The Palestinian Authority becomes the 123rd member of the International Criminal Court. The formal accession was marked with a ceremony at The Hague, in the Netherlands. The move gives the court jurisdiction over alleged crimes in Palestinian territories. Israel and the United States opposed the Palestinians' efforts to join the body.\n",
            "Amnesty International's annual report catalogs the use of state-sanctioned killing as a punitive measure. At least 607 people were executed around the world in 2014, compared to 778 in 2013. The U.S. remains one of the worst offenders for imposing capital punishment, with only Iran and Saudi Arabia executing more.\n",
            "Amnesty International releases its annual review of the death penalty worldwide. In Pakistan, the government lifted a six-year moratorium on the execution of civilians. Iran and Iraq executed people for \"terrorism,\" and other countries expanded the scope of capital crimes. There is no evidence that the threat of execution is more of a deterrent to crime than a prison sentence.\n",
            "Anne Frank died of typhus in a Nazi concentration camp at the age of 15. Researchers re-examined archives of the Red Cross, the International Training Service and the Bergen-Belsen Memorial. They concluded that Anne and Margot probably did not survive to March 1945 -- contradicting the date of death which had previously been determined.\n",
            "The student is no longer on campus and will face student conduct review. Officials are still trying to determine if other people were involved. The incident is one of several recent racist events to affect college students. Last month a fraternity at the University of Oklahoma had its charter removed.\n",
            "The Rev. Robert H. Schuller was diagnosed with esophageal cancer in August 2013. He was also the founder of the television ministry \"Hour of Power\" He sold a softer, gentler message, which borrowed heavily from the father of the feel-good gospel. His confident, breezy version of Christianity drew hordes of seekers and lapsed Christians.\n",
            "Theia, a one-year-old bully breed mix, was hit by a car and buried in a field. She managed to stagger to a nearby farm, dirt-covered and emaciated. She suffered a dislocated jaw, leg injuries and a caved-in sinus cavity. A fundraising page has raised more than $10,000 for her care.\n",
            "Mohammad Javad Zarif is the Iranian foreign minister. He has been John Kerry's opposite number in securing a breakthrough in nuclear talks. He received a hero's welcome as he arrived in Iran on a sunny Friday morning. But there are some facts about Zarif that are less well-known.\n",
            "Bob Barker returned to \"The Price Is Right\" for the first time in eight years. The 91-year-old hosted the show for 35 years before stepping down in 2007. He handled the first price-guessing game, the classic \"Lucky Seven,\" before turning hosting duties over to Drew Carey.\n"
          ]
        }
      ],
      "source": [
        "!head 320_test.hypo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nmfO-Pj-7sYa"
      },
      "outputs": [],
      "source": [
        "!cp 320_test.hypo test.hypo\n",
        "!cp data/test.target test.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etI5Qu4o6tWm"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsPa-OjU7ASr"
      },
      "source": [
        "Follow https://github.com/pytorch/fairseq/tree/master/examples/bart to install *files2rouge*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4YkacBQyyke",
        "outputId": "81b3db13-85e7-4d7b-9aaa-54fbd09e2ded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Could not find or load main class edu.stanford.nlp.process.PTBTokenizer\n",
            "Caused by: java.lang.ClassNotFoundException: edu.stanford.nlp.process.PTBTokenizer\n",
            "Error: Could not find or load main class edu.stanford.nlp.process.PTBTokenizer\n",
            "Caused by: java.lang.ClassNotFoundException: edu.stanford.nlp.process.PTBTokenizer\n",
            "/bin/bash: files2rouge: command not found\n"
          ]
        }
      ],
      "source": [
        "!export CLASSPATH=/path/to/stanford-corenlp-full-2016-10-31/stanford-corenlp-3.7.0.jar\n",
        "\n",
        "# Tokenize hypothesis and target files.\n",
        "!cat test.hypo | java edu.stanford.nlp.process.PTBTokenizer -ioFileList -preserveLines > test.hypo.tokenized\n",
        "!cat test.target | java edu.stanford.nlp.process.PTBTokenizer -ioFileList -preserveLines > test.hypo.target\n",
        "!files2rouge test.hypo.tokenized test.hypo.target\n",
        "# Expected output: (ROUGE-2 Average_F: 0.21227)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5TfX3oz97yC_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "EL-attention_Demo.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
